{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e0eb4aa",
   "metadata": {},
   "source": [
    "## Scraping Data for the Last 15 Years: 2010â€“2024\n",
    "\n",
    "In this notebook, I use the functions defined in the `utils.py` file to scrape transplant data for all transplant centers in Italy over the past 15 years (2010â€“2024). The scraped data will be saved in the `data_raw` folder, organized by year and organ. \n",
    "\n",
    "Once collected, the data will be loaded, cleaned, and reshaped into a single consolidated DataFrame, which will serve as the foundation for further analysis and data visualization.\n",
    "\n",
    "To minimize the risk of data loss in case of an error during execution, I will perform the scraping in blocks of 3 to 5 years. This approach allows me to save partial results progressively and resume easily if something goes wrong during the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d2810",
   "metadata": {},
   "source": [
    "### ğŸ” Handling Missing Data from Previous Scraping Runs\n",
    "In case any organ-year combinations fail during scraping (e.g., due to stale element errors or loading delays), I can re-run the scraping selectively for the missing items after reviewing the console warnings or scrape reports.\n",
    "\n",
    "For example, if 2023-Fegato or 2023-Polmone were skipped, I can retry:\n",
    "\n",
    "```python\n",
    "organs = ['Fegato', 'Polmone']\n",
    "year = '2023'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "save_each_organ_table_for_year(driver, year=year, organs=organs, output_folder=f\"../data_raw/{year}\")\n",
    "driver.quit()\n",
    "```\n",
    "This strategy avoids repeating successful scrapes and ensures that all organ-year data is eventually collected in the correct folder structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ddbb47",
   "metadata": {},
   "source": [
    "### âš ï¸ Organs Skipped Due to Legitimate Absence of Data\n",
    "During scraping, some organ-year combinations like `2020-Intestino` and `2021-Intestino` may return timeout errors because **no transplants were performed for that organ in that year**.\n",
    "This is not a scraping failure but a reflection of the real data available on the website.\n",
    "\n",
    "Such cases can be skipped safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6322e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import scrape_year, reset_main_page, save_each_organ_table_for_year\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bfe4b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Starting scraping for year 2012...\n",
      "ğŸ”„ Scraping Rene data for 2012...\n",
      "[Error] 2012-Rene: Message: stale element reference: stale element not found\n",
      "  (Session info: chrome=137.0.7151.69); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x7ff794b8fea5+79173]\n",
      "\tGetHandleVerifier [0x0x7ff794b8ff00+79264]\n",
      "\t(No symbol) [0x0x7ff794949e5a]\n",
      "\t(No symbol) [0x0x7ff794960264]\n",
      "\t(No symbol) [0x0x7ff79495ed33]\n",
      "\t(No symbol) [0x0x7ff794952551]\n",
      "\t(No symbol) [0x0x7ff7949526b1]\n",
      "\t(No symbol) [0x0x7ff79495041f]\n",
      "\t(No symbol) [0x0x7ff794954be1]\n",
      "\t(No symbol) [0x0x7ff7949f22b4]\n",
      "\t(No symbol) [0x0x7ff7949c896a]\n",
      "\t(No symbol) [0x0x7ff7949f100d]\n",
      "\t(No symbol) [0x0x7ff7949c8743]\n",
      "\t(No symbol) [0x0x7ff7949914c1]\n",
      "\t(No symbol) [0x0x7ff794992253]\n",
      "\tGetHandleVerifier [0x0x7ff794e5a2dd+3004797]\n",
      "\tGetHandleVerifier [0x0x7ff794e5472d+2981325]\n",
      "\tGetHandleVerifier [0x0x7ff794e73380+3107360]\n",
      "\tGetHandleVerifier [0x0x7ff794baaa2e+188622]\n",
      "\tGetHandleVerifier [0x0x7ff794bb22bf+219487]\n",
      "\tGetHandleVerifier [0x0x7ff794b98df4+115860]\n",
      "\tGetHandleVerifier [0x0x7ff794b98fa9+116297]\n",
      "\tGetHandleVerifier [0x0x7ff794b7f558+11256]\n",
      "\tBaseThreadInitThunk [0x0x7ffc1285e8d7+23]\n",
      "\tRtlUserThreadStart [0x0x7ffc1391c34c+44]\n",
      "\n",
      "âš ï¸ Skipping Rene due to missing data.\n",
      "ğŸ”„ Scraping Fegato data for 2012...\n",
      "âœ… Saved: ../data_raw/2012/2012_Fegato.csv\n",
      "ğŸ”„ Scraping Cuore data for 2012...\n",
      "âœ… Saved: ../data_raw/2012/2012_Cuore.csv\n",
      "ğŸ”„ Scraping Polmone data for 2012...\n",
      "âœ… Saved: ../data_raw/2012/2012_Polmone.csv\n",
      "ğŸ”„ Scraping Pancreas data for 2012...\n",
      "âœ… Saved: ../data_raw/2012/2012_Pancreas.csv\n",
      "ğŸ”„ Scraping Intestino data for 2012...\n",
      "[Timeout] 2012-Intestino: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x7ff794b8fea5+79173]\n",
      "\tGetHandleVerifier [0x0x7ff794b8ff00+79264]\n",
      "\t(No symbol) [0x0x7ff794949e5a]\n",
      "\t(No symbol) [0x0x7ff7949a0586]\n",
      "\t(No symbol) [0x0x7ff7949a083c]\n",
      "\t(No symbol) [0x0x7ff7949f4247]\n",
      "\t(No symbol) [0x0x7ff7949c89af]\n",
      "\t(No symbol) [0x0x7ff7949f100d]\n",
      "\t(No symbol) [0x0x7ff7949c8743]\n",
      "\t(No symbol) [0x0x7ff7949914c1]\n",
      "\t(No symbol) [0x0x7ff794992253]\n",
      "\tGetHandleVerifier [0x0x7ff794e5a2dd+3004797]\n",
      "\tGetHandleVerifier [0x0x7ff794e5472d+2981325]\n",
      "\tGetHandleVerifier [0x0x7ff794e73380+3107360]\n",
      "\tGetHandleVerifier [0x0x7ff794baaa2e+188622]\n",
      "\tGetHandleVerifier [0x0x7ff794bb22bf+219487]\n",
      "\tGetHandleVerifier [0x0x7ff794b98df4+115860]\n",
      "\tGetHandleVerifier [0x0x7ff794b98fa9+116297]\n",
      "\tGetHandleVerifier [0x0x7ff794b7f558+11256]\n",
      "\tBaseThreadInitThunk [0x0x7ffc1285e8d7+23]\n",
      "\tRtlUserThreadStart [0x0x7ffc1391c34c+44]\n",
      "\n",
      "âš ï¸ Skipping Intestino due to missing data.\n",
      "âœ… Finished scraping for year 2012.\n",
      "ğŸ”„ Starting scraping for year 2011...\n",
      "ğŸ”„ Scraping Rene data for 2011...\n",
      "âœ… Saved: ../data_raw/2011/2011_Rene.csv\n",
      "ğŸ”„ Scraping Fegato data for 2011...\n",
      "âœ… Saved: ../data_raw/2011/2011_Fegato.csv\n",
      "ğŸ”„ Scraping Cuore data for 2011...\n",
      "[Timeout] 2011-Cuore: Message: \n",
      "\n",
      "âš ï¸ Skipping Cuore due to missing data.\n",
      "ğŸ”„ Scraping Polmone data for 2011...\n",
      "âœ… Saved: ../data_raw/2011/2011_Polmone.csv\n",
      "ğŸ”„ Scraping Pancreas data for 2011...\n",
      "âœ… Saved: ../data_raw/2011/2011_Pancreas.csv\n",
      "ğŸ”„ Scraping Intestino data for 2011...\n",
      "âœ… Saved: ../data_raw/2011/2011_Intestino.csv\n",
      "âœ… Finished scraping for year 2011.\n",
      "ğŸ”„ Starting scraping for year 2010...\n",
      "ğŸ”„ Scraping Rene data for 2010...\n",
      "âœ… Saved: ../data_raw/2010/2010_Rene.csv\n",
      "ğŸ”„ Scraping Fegato data for 2010...\n",
      "âœ… Saved: ../data_raw/2010/2010_Fegato.csv\n",
      "ğŸ”„ Scraping Cuore data for 2010...\n",
      "âœ… Saved: ../data_raw/2010/2010_Cuore.csv\n",
      "ğŸ”„ Scraping Polmone data for 2010...\n",
      "âœ… Saved: ../data_raw/2010/2010_Polmone.csv\n",
      "ğŸ”„ Scraping Pancreas data for 2010...\n",
      "âœ… Saved: ../data_raw/2010/2010_Pancreas.csv\n",
      "ğŸ”„ Scraping Intestino data for 2010...\n",
      "âœ… Saved: ../data_raw/2010/2010_Intestino.csv\n",
      "âœ… Finished scraping for year 2010.\n"
     ]
    }
   ],
   "source": [
    "organs = ['Rene', 'Fegato', 'Cuore', 'Polmone', 'Pancreas', 'Intestino']\n",
    "years = ['2012', '2011', '2010']\n",
    "\n",
    "for year in years:\n",
    "    try:\n",
    "        print(f\"ğŸ”„ Starting scraping for year {year}...\")\n",
    "        driver = webdriver.Chrome()\n",
    "        output_folder = f\"../data_raw/{year}\"\n",
    "        save_each_organ_table_for_year(driver, year=year, organs=organs, output_folder=output_folder)\n",
    "        print(f\"âœ… Finished scraping for year {year}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error while scraping year {year}: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d9cce",
   "metadata": {},
   "source": [
    "### ğŸ” Final Retry for Missing Data\n",
    "This is the final retry to collect data for `'Rene'` in **2012** and `'Cuore'` in **2011**, which were previously skipped during the loop despite being available on the website.\n",
    "\n",
    "With this final step, Iâ€™ve now successfully collected all available data for **all organs**, across **all transplant centers**, for **each year from 2010 to 2024**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89baf0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Scraping Rene data for 2012...\n",
      "âœ… Saved: ../data_raw/2012/2012_Rene.csv\n"
     ]
    }
   ],
   "source": [
    "#organs = ['Rene']\n",
    "#year = '2012'\n",
    "\n",
    "#driver = webdriver.Chrome()\n",
    "#save_each_organ_table_for_year(driver, year=year, organs=organs, output_folder=f\"../data_raw/{year}\")\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5197ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Scraping Cuore data for 2011...\n",
      "âœ… Saved: ../data_raw/2011/2011_Cuore.csv\n"
     ]
    }
   ],
   "source": [
    "#organs = ['Cuore']\n",
    "#year = '2011'\n",
    "\n",
    "#driver = webdriver.Chrome()\n",
    "#save_each_organ_table_for_year(driver, year=year, organs=organs, output_folder=f\"../data_raw/{year}\")\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f6f57c",
   "metadata": {},
   "source": [
    "### âœ… Scraping Summary\n",
    "With this notebook, I have completed the scraping of transplant data for:\n",
    "\n",
    "- **All organs**: Rene, Fegato, Cuore, Polmone, Pancreas, Intestino\n",
    "- **All planned years**: from 2010 to 2024\n",
    "- **All transplant centers** in Italy\n",
    "\n",
    "Each organ's data has been saved by year in the `data_raw/` folder following a structured directory layout.\n",
    "\n",
    "This dataset forms the complete raw foundation for building a unified and analysis-ready table. In the next step â€” as outlined in the notebook `06_Manipulating_DataFrames_to_build_one_single_DataFrame.ipynb` â€” I will:\n",
    "\n",
    "- Load these individual CSV files\n",
    "- Clean and reshape them\n",
    "- Consolidate everything into a single **pivoted long-format DataFrame**\n",
    "ready for data exploration and visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
